{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THÔNG TIN CHUNG VỀ NHÓM VÀ ĐỀ TÀI\n",
    "## Thành viên nhóm 19\n",
    "1612441 Phạm Quang Phước Nguyên\n",
    "\n",
    "1612451 Nguyễn Cao Nhân\n",
    "\n",
    "\n",
    "## Câu hỏi đặt ra là gì?\n",
    "Phân loại câu hỏi trong hệ thống hỏi và đáp của bệnh viện Đại học Y dược Thành phố Hồ Chí Minh. Các câu hỏi này được khách, người bệnh, người thân của người bệnh gửi đến bệnh viện thông qua nhiều kênh khác nhau: email, hỏi trực tiếp, fanpage, ... và được tổng hợp ở trang chủ của bệnh viện http://www.bvdaihoc.com.vn/, vào mục Giải đáp & Tư vấn http://gd1.bvdaihoc.com.vn/faqs_all.asp. Trong trang web này người ta phân các câu hỏi thành 30 danh mục khác nhau nhưng nhóm chỉ giải quyết câu hỏi trên 3 nhóm là **Dị ứng - Miễn dịch lâm sàng**, **Phổi** và **Tai mũi họng**\n",
    "\n",
    "## Lợi ích của việc trả lời câu hỏi này\n",
    "Trước đây thay vì có một người chịu trách nhiệm tiếp nhận câu hỏi sau đó đọc câu hỏi và chuyển tới đúng bác sĩ chuyên khoa để giải đáp (nên biết rằng người này không chỉ có việc xử lý câu hỏi, họ còn đảm nhận các công việc khác tại bệnh viện), có thể có ngày nào đó lượng câu hỏi đến khá nhiều khiến cho việc giải đáp không được kịp thời nhanh chóng. Hi vọng với cách phân loại tự động sẽ giúp tiết kiệm thời gian. (Nhóm có nghĩ tới các trường hợp bị phân loại sai, thì bác sĩ chuyên khoa khi đọc sẽ biết và gửi lại cho đúng chuyên khoa, hi vọng số lượng câu nhầm lẫn này sẽ không nhiều!)\n",
    "## Nguồn gốc của câu hỏi\n",
    "Ngay từ ban đầu nhóm có ý định làm một đề tài gì đó có liên quan tới sức khỏe, y tế nhưng khi tìm dữ liệu thì không có. Rất may sau khi nghe bài trình bày của Viettel về **Hệ thống chăm sóc khách hàng tự động trả lời câu hỏi** thì nhóm đã biết làm gì và quyết định tìm danh sách các bệnh viện có công bố phần hỏi đáp lên trang chủ, thì chỉ thấy có Bệnh viện Đại học Y dược Thành phố Hồ Chí Minh là có và khá nhiều câu hỏi. \n",
    "\n",
    "## Tính hợp pháp của dữ liệu\n",
    "Sau khi kiểm tra thì trang web không có tạo file robots.txt (kiểm tra ở http://www.bvdaihoc.com.vn/robots.txt và http://gd1.bvdaihoc.com.vn/faqs_all.asp/robots.txt). Sau khi hỏi ý kiến của thầy thì thầy phản hồi có thể chấp nhận được trong quy mô của môn học.\n",
    "\n",
    "## Mô tả dữ liệu\n",
    "Như đã trình bày, nhóm chỉ thu thập và làm việc trên 3 loại **Dị ứng - Miễn dịch lâm sàng**, **Phổi** và **Tai mũi họng**. Sau khi thu thập, nhóm có được 1159 câu hỏi, phân chia theo loại của chúng như sau:\n",
    "+ **Dị ứng - Miễn dịch lâm sàng**: có 225 câu hỏi\n",
    "+ **Phổi**: có 210 câu hỏi\n",
    "+ **Tai, mũi, họng**: có 724 câu hỏi\n",
    "\n",
    "Dữ liệu được lưu xuống file gồm 2 cột: cột thứ nhất là nội dung câu hỏi, cột thứ hai là id của loại mà chúng thuộc về. Quy ước \"Dị ứng - Miễn dịch lâm sàng\" là 0, \"Phổi\" là 1 và \"Tai mũi họng\" là 2.\n",
    "\n",
    "\n",
    "## Tính chính xác của dữ liệu\n",
    "Nhóm tin tưởng vào sự phân loại của trang web bệnh viện Đại học Y dược Thành phố Hồ Chí Minh!\n",
    "## Một số vấn đề khác của dữ liệu\n",
    "Như đã biết, dữ liệu dạng văn bản luôn gặp các vấn đề như: lỗi chính tả, viết tắt, viết ký hiệu... Việc này làm cho tập từ điển chứa rất nhiều từ không có giá trị, nhóm sẽ cố gắng để giảm bớt các từ không có ý nghĩa này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MỘT SỐ Ý CHÍNH TRONG CÁC BƯỚC MÀ NHÓM THỰC HIỆN\n",
    "## GIAI ĐOẠN 1: LẤY DỮ LIỆU\n",
    "## GIAI ĐOẠN 2: TIỀN XỬ LÝ DỮ LIỆU\n",
    "Sau khi chia tập dữ liệu ban đầu thành 3 tập train, validation, test với tỉ lệ 5-2.5-2.5, nhóm sẽ thực hiện các bước tiền xử lý sau: tạo \"từ điển từ\" từ tập train, tạo danh sách stopword và loại bỏ các từ này trong danh sách câu hỏi, sau đó chuyển đổi từng câu hỏi thành dạng vecto (bag of word), dùng một số phương pháp giảm số chiều do từ điển rất nhiều từ nên vecto đặc trưng sẽ rất dài. Khi có vecto dạng số ta có thể chọn mô hình để huấn luyện.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 1: LẤY DỮ LIỆU\n",
    "\n",
    "Trộn ngẫu nhiên lại\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thêm các thư viện cần thiết\n",
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "import time # Dùng để sleep chương trình\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225, 210, 724]\n"
     ]
    }
   ],
   "source": [
    "session = HTMLSession()\n",
    "url_of_page_1 = \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=48\"\n",
    "#Link của 3 trang đầu tiên của 3 nhóm chuyên khoa, các câu hỏi của từng nhóm chuyên khoa được lưu trong nhiều trang\n",
    "list_of_url_of_page_1 = [\"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=48\",\\\n",
    "                        \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=24\",\\\n",
    "                        \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=30\"]\n",
    "response_of_page_1 = session.get(url_of_page_1).html\n",
    "list_of_question = [] #Lưu các câu hỏi\n",
    "number_per_type = [] #Lưu id của loại chuyên khoa mà câu hỏi thuộc về #Quy ước: Dị ứng - Miễn dịch lâm sàn là loại 0, Phổi là loại 1, Tai mũi họng là loại 2\n",
    "for url_of_page_1 in list_of_url_of_page_1:\n",
    "    response_of_page_1 = session.get(url_of_page_1).html\n",
    "    #Lấy số trang của mỗi chuyên khoa\n",
    "    text_of_page = response_of_page_1.find(\"table\", first=True).text\n",
    "    number_of_page = re.findall(r\"trên tổng số ........\", text_of_page)[0]\n",
    "    number_of_page = re.findall(r\"\\d+\", number_of_page)\n",
    "    number_of_page = int(number_of_page[0])\n",
    "    #number_of_page\n",
    "    #Trang hiện tại, với mỗi trang sẽ lấy hết các câu hỏi có trong trang đó\n",
    "    number_start = len(list_of_question)\n",
    "    for page_i in range(1,number_of_page+1):\n",
    "        url_of_page_i = url_of_page_1 + \"&page=\" + str(page_i)\n",
    "        #print(url_of_page_i)\n",
    "        response_of_page_i = session.get(url_of_page_i).html\n",
    "        question = response_of_page_i.find(\"#AutoNumber6\")[1]\n",
    "        #Mỗi câu hỏi sẽ được lưu trong 1 thẻ \"tr\"\n",
    "        number_of_tr = len(question.find(\"tr\"))\n",
    "        number_of_tr\n",
    "        for i in range(1, len(question.find(\"tr\"))):\n",
    "            content = question.find(\"tr\")[i].text #câu hỏi thứ i\n",
    "            content = re.findall(r\".*\", content)[2] # trích xuất nội dung câu hỏi ra\n",
    "            #Thêm câu hỏi vào danh sách\n",
    "            list_of_question.append(content)\n",
    "        #print(url_of_page_i)\n",
    "    number_end = len(list_of_question)\n",
    "    number_of_this_type = number_end - number_start\n",
    "    number_per_type.append(number_of_this_type)\n",
    "\n",
    "len(list_of_question) #đúng là 1159\n",
    "print(number_per_type) #đúng là [225, 210, 724]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# print([item for item, count in collections.Counter(list_of_question).items() if count > 1]) #Có 3 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tạo cột nhóm chuyên khoa của các câu hỏi\n",
    "type_of_question = [] #Đúng là 0-239,240-459,460-739\n",
    "for x in range(len(number_per_type)):\n",
    "    for i in range(number_per_type[x]):\n",
    "        type_of_question.append(x)\n",
    "len(type_of_question) #1159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chào BS. Năm nay tôi 69 tuổi. Thỉnh thoảng khi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chào BS, Cho mình hỏi trên bệnh viện mình có x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BS cho em hỏi, em năm nay 33t, đã có gia đình,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Em uống thuốc nhưng cơ thể không chịu được thu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chào bác sĩ. Em là nữ (93) em bị dị ứng nổi mề...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Type\n",
       "0  Chào BS. Năm nay tôi 69 tuổi. Thỉnh thoảng khi...     0\n",
       "1  Chào BS, Cho mình hỏi trên bệnh viện mình có x...     0\n",
       "2  BS cho em hỏi, em năm nay 33t, đã có gia đình,...     0\n",
       "3  Em uống thuốc nhưng cơ thể không chịu được thu...     0\n",
       "4  Chào bác sĩ. Em là nữ (93) em bị dị ứng nổi mề...     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ghi vào dataFrame và lưu xuống File \"crawQuestion.csv\"\n",
    "data = {'Question':list_of_question,'Type':type_of_question}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"crawQuestion.csv\",index = False, header=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 2: TIỀN XỬ LÝ DỮ LIỆU\n",
    "Đọc dữ liệu, tách thành tập train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chia ngẫu nhiên nhưng đếm xem mỗi loại của từng tập ra sao\n",
    "#Làm sao chia mak đảm bảo có đủ 3 loại???\n",
    "# df_copy = df.copy()\n",
    "# train_set = df_copy.sample(frac=0.5, random_state=0)\n",
    "# val_test_set = df_copy.drop(train_set.index)\n",
    "# val_test_set_copy = val_test_set.copy()\n",
    "# val_set = val_test_set_copy.sample(frac=0.5, random_state=0)\n",
    "# test_set = val_test_set_copy.drop(val_set.index)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Tách X và y\n",
    "\n",
    "X_df = df[\"Question\"]\n",
    "y_df = df[\"Type\"]\n",
    "\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_df, y_df, test_size=0.5, \n",
    "                                                              stratify=y_df, random_state=0)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, \n",
    "                                                              stratify=y_val_and_test, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579 290 290\n",
      "579 290 290\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len( X_val), len(X_test)) #579, 290, 290\n",
    "print(len(y_train), len( y_val), len(y_test)) #579, 290, 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89     Thứ 4 (6/1), e tái khám sau cắt trĩ. Trước đó ...\n",
       "561    cho em hỏi chi phí nội soi cổ họng tại bệnh vi...\n",
       "63     Chào Bác sĩ, Cách đây một tuần, mẹ cháu (năm n...\n",
       "Name: Question, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    362\n",
      "0    112\n",
      "1    105\n",
      "Name: Type, dtype: int64\n",
      "2    181\n",
      "0     56\n",
      "1     53\n",
      "Name: Type, dtype: int64\n",
      "2    181\n",
      "0     57\n",
      "1     52\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Xem các số lượng các loại trong từng tập, note kết quả để thầy chạy sẽ dò đáp án\n",
    "print(y_train.value_counts()) #112,105,362\n",
    "print(y_val.value_counts()) #56,53,181\n",
    "print(y_test.value_counts()) #57,52,181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÔNG ĐOẠN TIỀN XỬ LÝ CHÍNH THỨC BẮT ĐẦU\n",
    "#Tách từ, stop words, tạo từ điển, làm sao giảm cho ít chiều lại thôi\n",
    "#Dấu 3 chấm, viết hoa thường phân biệt\n",
    "#List stop word: PGS, TS, ....\n",
    "# import pyvi\n",
    "# from pyvi import ViTokenizer\n",
    "# class NLP(object):\n",
    "#     def __init__(self, text = None):\n",
    "#         self.text = text\n",
    "#         self.__set_stopwords()\n",
    "\n",
    "#     def segmentation(self):\n",
    "#         return ViTokenizer.tokenize(self.text)\n",
    "    \n",
    "# ViTokenizer.tokenize(X_train.iloc[0])    \n",
    "\n",
    "# SPECIAL_CHARACTER = '0123456789%@$.,=+-!;/()*\"&^:#|\\n\\t\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(252 unique tokens: ['(', '(6/1),', '(ở', '4', 'Hiện']...)\n",
      "{'(': 0, '(6/1),': 1, '(ở': 2, '4': 3, 'Hiện': 4, 'Sẵn': 5, 'Thứ': 6, 'Trước': 7, 'Và': 8, 'biết': 9, 'chó': 10, 'chó,': 11, 'chưa': 12, 'chưa.': 13, 'còn': 14, 'có': 15, 'cũng': 16, 'cần': 17, 'cắt': 18, 'dịp': 19, 'e': 20, 'em': 21, 'giun': 22, 'giờ': 23, 'huyện)': 24, 'hàng': 25, 'hết': 26, 'khoa': 27, 'khám': 28, 'không': 29, 'không?)': 30, 'lại': 31, 'lấy': 32, 'mẫn': 33, 'nghiệm': 34, 'ngứa.': 35, 'nhiễm': 36, 'nhưng': 37, 'nào?': 38, 'này': 39, 'nổi': 40, 'phòng': 41, 'quy': 42, 'sau': 43, 'số': 44, 'thế': 45, 'thứ': 46, 'trình': 47, 'trĩ.': 48, 'trị': 49, 'tái': 50, 'tự': 51, 'và': 52, 'vào': 53, 'vẫn': 54, 'xem': 55, 'xin': 56, 'xét': 57, 'xếp': 58, 'đang': 59, 'điều': 60, 'đó': 61, 'đũa': 62, 'định': 63, 'đỏ': 64, 'bao': 65, 'bệnh': 66, 'chi': 67, 'cho': 68, 'cổ': 69, 'họng': 70, 'hỏi': 71, 'là': 72, 'nhiêu': 73, 'nội': 74, 'phí': 75, 'soi': 76, 'tại': 77, 'viện': 78, 'ạ': 79, '(năm': 80, '(đỏ': 81, '1,': 82, '2': 83, '52': 84, 'Bác': 85, 'Chào': 86, 'Chỉ': 87, 'Cách': 88, 'Cảm': 89, 'Hôm': 90, 'Khoa': 91, 'Sau': 92, 'Vậy': 93, 'bác': 94, 'bị': 95, 'cháu': 96, 'cả': 97, 'gì': 98, 'hay': 99, 'hiện': 100, 'hết.': 101, 'hợp?': 102, 'khuôn': 103, 'khác.': 104, 'mặt': 105, 'mặt,': 106, 'mẹ': 107, 'mề': 108, 'một': 109, 'nay': 110, 'nay,': 111, 'ngày': 112, 'như': 113, 'nào': 114, 'nên': 115, 'nó': 116, 'phù': 117, 'rượu).': 118, 'sĩ': 119, 'sĩ,': 120, 'sĩ.': 121, 'thì': 122, 'trên.': 123, 'tuần,': 124, 'tuổi)': 125, 'tượng': 126, 'uống': 127, 'đây': 128, 'đưa': 129, 'ơn': 130, 'ở': 131, ',': 132, '1': 133, '10': 134, '30.11.2010': 135, 'BV': 136, 'BÁC': 137, 'BÊN': 138, 'BẠCH': 139, 'BẢO': 140, 'BỆNH': 141, 'BỊ': 142, 'CHO': 143, 'CHÂN': 144, 'CHỐNG': 145, 'CHỮA': 146, 'CM,': 147, 'CẢM': 148, 'EM': 149, 'GÌ,': 150, 'HƠN': 151, 'KHOA': 152, 'KHOẢNG': 153, 'KHUYÊN': 154, 'KHÁM': 155, 'KHÁM,': 156, 'KIÊNG': 157, 'KO': 158, 'LO,': 159, 'LÀ': 160, 'LÀNH': 161, 'LỜI': 162, 'MIỆNG)': 163, 'MONG': 164, 'MÁ(GẦN': 165, 'MẠCH': 166, 'NAY': 167, 'NGHIỆM': 168, 'NGÀY': 169, 'NÊN': 170, 'PHÁT': 171, 'RẤT': 172, 'SAO': 173, 'SĨ': 174, 'SĨ!': 175, 'SĨ:': 176, 'THUỐC': 177, 'THÀNH': 178, 'THƯA': 179, 'TINH': 180, 'TO': 181, 'TRIỂN': 182, 'TÍ,': 183, 'TÔI': 184, 'TẠI': 185, 'U': 186, 'UỐNG': 187, 'VIÊM': 188, 'VIÊN': 189, 'VÀ': 190, 'XIN': 191, 'XÉT': 192, 'ĂN': 193, 'ĐA': 194, 'ĐAU': 195, 'ĐI': 196, 'ĐÀNẴNG': 197, 'ĐÂU?': 198, 'ĐẾN': 199, 'ƠN': 200, 'Ở': 201, '.': 202, '?': 203, '?phải': 204, 'biến': 205, 'chấm': 206, 'chỉ': 207, 'chứng': 208, 'các': 209, 'cảm': 210, 'dẫn': 211, 'dứt': 212, 'gian': 213, 'giữa': 214, 'gữa': 215, 'hậu': 216, 'hắn': 217, 'hồi': 218, 'khỏi': 219, 'khỏi,': 220, 'làm': 221, 'lâu': 222, 'lưu': 223, 'mong': 224, 'màn': 225, 'màng': 226, 'mãn': 227, 'mổ': 228, 'nhiều': 229, 'nhĩ': 230, 'những': 231, 'năm': 232, 'nằm': 233, 'phẫu': 234, 'sớm': 235, 'tai': 236, 'thuật': 237, 'thêm': 238, 'thư': 239, 'thời': 240, 'thủng': 241, 'trước': 242, 'tính': 243, 'viêm': 244, 'vá': 245, 'về': 246, 'ý': 247, 'điểm': 248, 'đâu': 249, 'đến': 250, 'đỡ': 251}\n"
     ]
    }
   ],
   "source": [
    "temp  = X_train.iloc[0:5]\n",
    "temp = temp.tolist()\n",
    "documents = temp\n",
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# Get information about the dictionary\n",
    "print(dictionary)\n",
    "type(dictionary)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÁCH CHUYỂN DATA THÀNH VECTO CỦA DICTIONARY, THỬ TRÊN DATA NHỎ TRƯỚC\n",
    "# tmp = temp[0].split()\n",
    "# tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = dictionary.doc2bow(tmp)\n",
    "# vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureExtraction(object):\n",
    "#     def __build_dataset(self):\n",
    "#         self.features = []\n",
    "#         self.labels = []\n",
    "#         i = 0\n",
    "#         for d in self.data:\n",
    "#             i += 1\n",
    "#             print( \"Step {} / {}\".format(i, len(self.data)))\n",
    "#             self.features.append(self.get_dense(d['content']))\n",
    "#             self.labels.append(d['category'])\n",
    "\n",
    "#     def get_dense(self, text):\n",
    "#         self.__load_dictionary()\n",
    "#         words = NLP(text).get_words_feature()\n",
    "#         # Bag of words\n",
    "#         vec = self.dictionary.doc2bow(words)\n",
    "#         dense = list(matutils.corpus2dense([vec], num_terms=len(self.dictionary)).T[0])\n",
    "#         return dense\n",
    "\n",
    "#     def get_data_and_label(self):\n",
    "#         self.__build_dataset()\n",
    "#         return self.features, self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureExtract = FeatureExtraction()\n",
    "# FeatureExtract.get_dense(temp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 3: TẠO PINELINE TỪ ĐẦU ĐẾN CUỐI VÀ LỰA CHỌN MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca giảm chiều\n",
    "#neural chạy nhanh không ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 4: ÁP DỤNG MÔ HÌNH TRÊN TẬP TEST ĐỂ RA KẾT QUẢ SAU CÙNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
