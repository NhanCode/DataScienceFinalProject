{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THÔNG TIN CHUNG VỀ NHÓM VÀ ĐỀ TÀI\n",
    "## Thành viên nhóm 19\n",
    "1612441 Phạm Quang Phước Nguyên\n",
    "\n",
    "1612451 Nguyễn Cao Nhân\n",
    "\n",
    "\n",
    "## Câu hỏi đặt ra là gì?\n",
    "Phân loại câu hỏi trong hệ thống hỏi và đáp của bệnh viện Đại học Y dược Thành phố Hồ Chí Minh. Các câu hỏi này được khách, người bệnh, người thân của người bệnh gửi đến bệnh viện thông qua nhiều kênh khác nhau: email, hỏi trực tiếp, fanpage, ... và được tổng hợp ở trang chủ của bệnh viện http://www.bvdaihoc.com.vn/, vào mục Giải đáp & Tư vấn http://gd1.bvdaihoc.com.vn/faqs_all.asp. Trong trang web này người ta phân các câu hỏi thành 30 danh mục khác nhau nhưng nhóm chỉ giải quyết câu hỏi trên 3 nhóm là **Dị ứng - Miễn dịch lâm sàng**, **Phổi** và **Tai mũi họng**.\n",
    "\n",
    "## Lợi ích của việc trả lời câu hỏi này?\n",
    "Trước đây thay vì có một người chịu trách nhiệm tiếp nhận câu hỏi sau đó đọc câu hỏi và chuyển tới đúng bác sĩ chuyên khoa để giải đáp (nên biết rằng người này không chỉ có việc xử lý câu hỏi, họ còn đảm nhận các công việc khác tại bệnh viện), có thể có ngày nào đó lượng câu hỏi đến khá nhiều khiến cho việc giải đáp không được kịp thời nhanh chóng. Hi vọng với cách phân loại tự động sẽ giúp tiết kiệm thời gian. (Nhóm có nghĩ tới các trường hợp bị phân loại sai, thì bác sĩ chuyên khoa khi đọc sẽ biết và gửi lại cho đúng chuyên khoa, hi vọng số lượng câu nhầm lẫn này sẽ không nhiều!)\n",
    "## Nguồn gốc của câu hỏi?\n",
    "Ngay từ ban đầu nhóm có ý định làm một đề tài gì đó có liên quan tới sức khỏe, y tế nhưng khi tìm dữ liệu thì không có. Rất may sau khi nghe bài trình bày của Viettel về **Hệ thống chăm sóc khách hàng tự động trả lời câu hỏi** tại Zalo AI Summit 2019 thì nhóm đã biết làm gì và quyết định tìm danh sách các bệnh viện có công bố phần hỏi đáp lên trang chủ, thì chỉ thấy có Bệnh viện Đại học Y dược Thành phố Hồ Chí Minh là có và khá nhiều câu hỏi. \n",
    "\n",
    "## Tính hợp pháp của dữ liệu?\n",
    "Sau khi kiểm tra thì trang web không có tạo file robots.txt (kiểm tra ở http://www.bvdaihoc.com.vn/robots.txt và http://gd1.bvdaihoc.com.vn/faqs_all.asp/robots.txt). Sau khi hỏi ý kiến của thầy thì thầy phản hồi có thể chấp nhận được trong quy mô của môn học.\n",
    "\n",
    "## Mô tả dữ liệu?\n",
    "Như đã trình bày, nhóm chỉ thu thập và làm việc trên 3 loại **Dị ứng - Miễn dịch lâm sàng**, **Phổi** và **Tai mũi họng**. Sau khi thu thập, nhóm có được 1159 câu hỏi, phân chia theo loại của chúng như sau:\n",
    "+ **Dị ứng - Miễn dịch lâm sàng**: có 225 câu hỏi\n",
    "+ **Phổi**: có 210 câu hỏi\n",
    "+ **Tai, mũi, họng**: có 724 câu hỏi\n",
    "\n",
    "Dữ liệu được lưu xuống file gồm 2 cột: cột thứ nhất là nội dung câu hỏi, cột thứ hai là id của loại mà chúng thuộc về. Quy ước \"Dị ứng - Miễn dịch lâm sàng\" là 0, \"Phổi\" là 1 và \"Tai mũi họng\" là 2.\n",
    "\n",
    "\n",
    "## Tính chính xác của dữ liệu?\n",
    "Nhóm tin tưởng vào sự phân loại của trang web bệnh viện Đại học Y dược Thành phố Hồ Chí Minh!\n",
    "## Một số vấn đề khác của dữ liệu?\n",
    "Như đã biết, dữ liệu dạng văn bản luôn gặp các vấn đề như: lỗi chính tả, viết tắt, viết ký hiệu... Việc này làm cho tập từ điển chứa rất nhiều từ không có giá trị, nhóm sẽ cố gắng để giảm bớt các từ không có ý nghĩa này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MỘT SỐ Ý CHÍNH TRONG CÁC BƯỚC MÀ NHÓM THỰC HIỆN\n",
    "## GIAI ĐOẠN 1: LẤY DỮ LIỆU\n",
    "## GIAI ĐOẠN 2: TIỀN XỬ LÝ DỮ LIỆU\n",
    "Sau khi chia tập dữ liệu ban đầu thành 3 tập train, validation, test với tỉ lệ 6-2-2, nhóm sẽ thực hiện các bước tiền xử lý sau: tạo \"từ điển từ\" từ tập train, tạo danh sách stopword và loại bỏ các từ này trong danh sách câu hỏi, sau đó chuyển đổi từng câu hỏi thành dạng vecto (bag of word), dùng một số phương pháp giảm số chiều do từ điển rất nhiều từ nên vecto đặc trưng sẽ rất dài. Khi có vecto dạng số ta có thể chọn mô hình để huấn luyện.\n",
    "## GIAI ĐOẠN 3: TẠO PINELINE TỪ ĐẦU ĐẾN CUỐI, LỰA CHỌN MÔ HÌNH\n",
    "\n",
    "Thay đổi tham số anpha trong mô hình Neural Network để tìm ra được mô hình có độ lỗi trên tập val là thấp nhất. Sau đó với anpha tìm được, ta huấn luyện mô hình trên tập train + val.\n",
    "\n",
    "## GIAI ĐOẠN 4: ÁP DỤNG MÔ HÌNH TRÊN TẬP TEST ĐỂ RA KẾT QUẢ SAU CÙNG¶\n",
    "\n",
    "Dùng mô hình tìm được ở giai đoạn 3 để dự đoán và tính độ lỗi trên tập test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 1: LẤY DỮ LIỆU\n",
    "\n",
    "Trộn ngẫu nhiên lại\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thêm các thư viện cần thiết\n",
    "from requests_html import HTMLSession\n",
    "import requests\n",
    "import time # Dùng để sleep chương trình\n",
    "import datetime as dt # Dùng để xử lý dữ liệu thời gian\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split #Chia tập dữ liệu\n",
    "#Tạo từ điển từ\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159\n",
      "[225, 210, 724]\n"
     ]
    }
   ],
   "source": [
    "session = HTMLSession()\n",
    "url_of_page_1 = \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=48\"\n",
    "#Link của 3 trang đầu tiên của 3 nhóm chuyên khoa, các câu hỏi của từng nhóm chuyên khoa được lưu trong nhiều trang\n",
    "list_of_url_of_page_1 = [\"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=48\",\\\n",
    "                        \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=24\",\\\n",
    "                        \"http://gd1.bvdaihoc.com.vn/faqs_all.asp?Category=30\"]\n",
    "response_of_page_1 = session.get(url_of_page_1).html\n",
    "list_of_question = [] #Lưu các câu hỏi\n",
    "number_per_type = [] #Lưu id của loại chuyên khoa mà câu hỏi thuộc về #Quy ước: Dị ứng - Miễn dịch lâm sàn là loại 0, Phổi là loại 1, Tai mũi họng là loại 2\n",
    "for url_of_page_1 in list_of_url_of_page_1:\n",
    "    response_of_page_1 = session.get(url_of_page_1).html\n",
    "    #Lấy số trang của mỗi chuyên khoa\n",
    "    text_of_page = response_of_page_1.find(\"table\", first=True).text\n",
    "    number_of_page = re.findall(r\"trên tổng số ........\", text_of_page)[0]\n",
    "    number_of_page = re.findall(r\"\\d+\", number_of_page)\n",
    "    number_of_page = int(number_of_page[0])\n",
    "    #number_of_page\n",
    "    #Trang hiện tại, với mỗi trang sẽ lấy hết các câu hỏi có trong trang đó\n",
    "    number_start = len(list_of_question)\n",
    "    for page_i in range(1,number_of_page+1):\n",
    "        url_of_page_i = url_of_page_1 + \"&page=\" + str(page_i)\n",
    "        #print(url_of_page_i)\n",
    "        response_of_page_i = session.get(url_of_page_i).html\n",
    "        question = response_of_page_i.find(\"#AutoNumber6\")[1]\n",
    "        #Mỗi câu hỏi sẽ được lưu trong 1 thẻ \"tr\"\n",
    "        number_of_tr = len(question.find(\"tr\"))\n",
    "        number_of_tr\n",
    "        for i in range(1, len(question.find(\"tr\"))):\n",
    "            content = question.find(\"tr\")[i].text #câu hỏi thứ i\n",
    "            content = re.findall(r\".*\", content)[2] # trích xuất nội dung câu hỏi ra\n",
    "            #Thêm câu hỏi vào danh sách\n",
    "            list_of_question.append(content)\n",
    "        #print(url_of_page_i)\n",
    "    number_end = len(list_of_question)\n",
    "    number_of_this_type = number_end - number_start\n",
    "    number_per_type.append(number_of_this_type)\n",
    "print(len(list_of_question)) #đúng là 1159\n",
    "print(number_per_type) #đúng là [225, 210, 724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# print([item for item, count in collections.Counter(list_of_question).items() if count > 1]) #Có 3 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tạo cột nhóm chuyên khoa của các câu hỏi\n",
    "type_of_question = [] #Đúng là 0-239,240-459,460-739\n",
    "for x in range(len(number_per_type)):\n",
    "    for i in range(number_per_type[x]):\n",
    "        type_of_question.append(x)\n",
    "len(type_of_question) #1159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chào BS. Năm nay tôi 69 tuổi. Thỉnh thoảng khi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chào BS, Cho mình hỏi trên bệnh viện mình có x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BS cho em hỏi, em năm nay 33t, đã có gia đình,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Em uống thuốc nhưng cơ thể không chịu được thu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chào bác sĩ. Em là nữ (93) em bị dị ứng nổi mề...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Type\n",
       "0  Chào BS. Năm nay tôi 69 tuổi. Thỉnh thoảng khi...     0\n",
       "1  Chào BS, Cho mình hỏi trên bệnh viện mình có x...     0\n",
       "2  BS cho em hỏi, em năm nay 33t, đã có gia đình,...     0\n",
       "3  Em uống thuốc nhưng cơ thể không chịu được thu...     0\n",
       "4  Chào bác sĩ. Em là nữ (93) em bị dị ứng nổi mề...     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ghi vào dataFrame và lưu xuống File \"crawQuestion.csv\"\n",
    "data = {'Question':list_of_question,'Type':type_of_question}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"crawQuestion.csv\",index = False, header=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 2: TIỀN XỬ LÝ DỮ LIỆU\n",
    "Đọc dữ liệu, tách thành tập train, test, validation\n",
    "\n",
    "Tách từ, StopWord, PCA, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695 232 232\n",
      "695 232 232\n",
      "2    434\n",
      "0    135\n",
      "1    126\n",
      "Name: Type, dtype: int64\n",
      "2    145\n",
      "0     45\n",
      "1     42\n",
      "Name: Type, dtype: int64\n",
      "2    145\n",
      "0     45\n",
      "1     42\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tách X và y\n",
    "X_df = df[\"Question\"]\n",
    "y_df = df[\"Type\"]\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X_df, y_df, test_size=0.4, \n",
    "                                                              stratify=y_df, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, \n",
    "                                                              stratify=y_val_and_test, random_state=0)\n",
    "print(len(X_train), len( X_val), len(X_test)) #695 232 232\n",
    "print(len(y_train), len( y_val), len(y_test)) #695 232 232\n",
    "#Xem các số lượng các loại trong từng tập\n",
    "print(y_train.value_counts()) #135, 126, 434\n",
    "print(y_val.value_counts()) #45, 42, 145\n",
    "print(y_test.value_counts()) #45, 42, 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TẠO TỪ ĐIỂN TỪ TỪ TẬP TRAIN\n",
    "class bagOfWord():\n",
    "    def fit(self, X_data, y=None): #X_data phải là list, nhớ có None đây\n",
    "        X_data = X_data.tolist()\n",
    "        #Tách từ\n",
    "        texts = [[text for text in doc.split()] for doc in X_data]\n",
    "        #Tạo từ điển\n",
    "        dictionary = corpora.Dictionary(texts)\n",
    "        #Chuyển thành dạng \"key-value\" tương ứng với \"từ - id_từ\", id_từ bắt đầu từ 0\n",
    "        self.dictionary = dictionary.token2id #key- value (#từ-số, sao id2token bị lỗi ???)\n",
    "        return self\n",
    "    def transform(self, X_data, y=None): #X_data phải là list\n",
    "        X_data = X_data.tolist()\n",
    "        matrix = np.zeros((len(X_data),len(list(self.dictionary))), dtype=int) #số dòng là số mẫu dữ liệu, số cột là số từ trong dictionary\n",
    "        for tmp in X_data:\n",
    "            for word in tmp.split(): #ban đầu không split() là ra ký tự luôn\n",
    "                if word in self.dictionary.keys():\n",
    "                    matrix[X_data.index(tmp),self.dictionary[word]] += 1\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(695, 7019)\n",
      "(232, 7019)\n"
     ]
    }
   ],
   "source": [
    "#Test thử class bagOfWord():\n",
    "bag = bagOfWord()\n",
    "bag.fit(X_train)\n",
    "data1 = bag.transform(X_train)\n",
    "data2 = bag.transform(X_test)\n",
    "sum(data2[2])\n",
    "print(data1.shape) # (số dòng, số cột) = (số mẫu dữ liệu, số chiều của veto đặc trưng)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7019\n"
     ]
    }
   ],
   "source": [
    "#Số lượng từ vựng trong từ điển\n",
    "print(len(bag.dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 7019)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách từ, StopWord, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=100)\n",
    "# pca.fit(data2)\n",
    "# #PCA(n_components=2)\n",
    "# # print(pca.explained_variance_ratio_)\n",
    "# # print(pca.singular_values_)\n",
    "# data = pca.fit_transform(data2)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 3: TẠO PINELINE TỪ ĐẦU ĐẾN CUỐI, SO SÁNH, ĐÁNH GIÁ VÀ LỰA CHỌN MÔ HÌNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PHẦN CODE THỬ NGHIỆM NHIỀU MÔ HÌNH VỚI THAM SỐ: ....\n",
    "#Các tham số dự định: alpha, số chiều của dic, số từ stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.14388489208633093, 0.0, 0.0, 0.0, 6.330935251798561, 3.597122302158273, 2.014388489208633, 1.1510791366906474, 19.568345323741006, 16.834532374100718, 15.53956834532374, 15.251798561151078, 37.55395683453238, 37.55395683453238, 37.55395683453238, 37.55395683453238]\n",
      "[22.413793103448278, 15.086206896551724, 15.948275862068966, 13.793103448275861, 17.67241379310345, 16.379310344827587, 15.517241379310345, 13.793103448275861, 15.517241379310345, 12.931034482758621, 14.655172413793101, 14.224137931034484, 20.689655172413794, 19.396551724137932, 18.96551724137931, 18.53448275862069, 37.5, 37.5, 37.5, 37.5]\n",
      "\n",
      "\n",
      "12.931034482758621 10 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finish!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo full pipeline\n",
    "#Tạo mô hình Neural Net\n",
    "clf = MLPClassifier(hidden_layer_sizes=(20), alpha=0.1, activation='tanh', solver='lbfgs', random_state=0, max_iter=500)\n",
    "full_pipeline = Pipeline([(\"BagOfWord\",bagOfWord()), (\"PCA\", pca) ,(\"NN\", clf)])\n",
    "# train_X_df, val_X_df, train_y_sr, val_y_sr\n",
    "# Thử nghiệm với các giá trị khác nhau của các siêu tham số\n",
    "# và chọn ra các giá trị tốt nhất\n",
    "train_errs = []\n",
    "val_errs = []\n",
    "alphas = [0.1, 1, 10, 100, 1000]\n",
    "components = [50, 100, 150, 200]\n",
    "\n",
    "\n",
    "best_val_err = float('inf')\n",
    "\n",
    "best_alpha = None\n",
    "best_component = None\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    for component in components:\n",
    "        full_pipeline.set_params(PCA__n_components=component, NN__alpha=alpha)\n",
    "        full_pipeline.fit(X_train,y_train)\n",
    "\n",
    "        #Dự đoán và tính độ lỗi trên tập train\n",
    "        train = full_pipeline.predict(X_train)\n",
    "        train_err = np.mean(train != y_train)*100\n",
    "        train_errs.append(train_err)\n",
    "        #Dự đoán và tính độ lỗi trên tập val\n",
    "        val = full_pipeline.predict(X_val)\n",
    "        val_err = np.mean(val != y_val)*100\n",
    "        val_errs.append(val_err)\n",
    "        #Tìm độ lỗi thấp nhất trên tập test\n",
    "        if val_err < best_val_err:\n",
    "            best_val_err = val_err\n",
    "            best_alpha = alpha \n",
    "            best_component = component\n",
    "print(train_errs)        \n",
    "print(val_errs)\n",
    "print(\"\\n\")\n",
    "print(best_val_err, best_alpha, best_component)\n",
    "'Finish!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trực quan hóa kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695 232 927\n",
      "695 232 927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('BagOfWord', <__main__.bagOfWord object at 0x000001E8373F70F0>), ('PCA', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('NN', MLPClassifier(activation='tanh', alpha=10, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.9...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Huấn luyện lần cuối trên tập train+val\n",
    "X_train_val = X_train; y_train_val = y_train\n",
    "X_train_val = X_train_val.append(X_val); y_train_val = y_train_val.append(y_val)\n",
    "print(len(X_train), len(X_val), len(X_train_val))\n",
    "print(len(y_train), len(y_val), len(y_train_val))\n",
    "\n",
    "full_pipeline.set_params(PCA__n_components=best_component, NN__alpha=best_alpha)\n",
    "#full_pipeline.set_params(NN__alpha=0.1)\n",
    "full_pipeline.fit(X_train_val,y_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIAI ĐOẠN 4: ÁP DỤNG MÔ HÌNH TRÊN TẬP TEST ĐỂ RA KẾT QUẢ SAU CÙNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ lỗi là:  14.224137931034484\n",
      "Độ chính xác là:  85.77586206896552\n"
     ]
    }
   ],
   "source": [
    "#Đánh giá trên tập test\n",
    "test = full_pipeline.predict(X_test)\n",
    "test_err = np.mean(test != y_test)*100\n",
    "print(\"Độ lỗi là: \", test_err)\n",
    "print(\"Độ chính xác là: \", 100 - test_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
